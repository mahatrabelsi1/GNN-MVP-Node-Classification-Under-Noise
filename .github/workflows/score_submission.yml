name: Score Submission (PR)

on:
  pull_request:
    paths:
      - "submissions/inbox/**/predictions.csv"
      - "submissions/inbox/**/metadata.json"

permissions:
  contents: read
  pull-requests: write

jobs:
  score:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          set -e
          python -m pip install --upgrade pip
          pip install pandas scikit-learn numpy

      - name: Restore hidden test labels (secret)
        shell: bash
        env:
          P1: ${{ secrets.TEST_LABELS_B64_01 }}
          P2: ${{ secrets.TEST_LABELS_B64_02 }}
          P3: ${{ secrets.TEST_LABELS_B64_03 }}
          P4: ${{ secrets.TEST_LABELS_B64_04 }}
          P5: ${{ secrets.TEST_LABELS_B64_05 }}
          P6: ${{ secrets.TEST_LABELS_B64_06 }}
          P7: ${{ secrets.TEST_LABELS_B64_07 }}
          P8: ${{ secrets.TEST_LABELS_B64_08 }}
        run: |
          set -e
          mkdir -p data/private

          # If secrets are missing (e.g., PR from fork), fail with a clear message
          if [ -z "$P1$P2$P3$P4$P5$P6$P7$P8" ]; then
            echo "❌ TEST_LABELS_B64_01..08 secrets are not available to this workflow run."
            echo "If this PR is from a fork, GitHub does not expose secrets to it."
            exit 1
          fi

          printf "%s%s%s%s%s%s%s%s" "$P1" "$P2" "$P3" "$P4" "$P5" "$P6" "$P7" "$P8" | base64 -d > data/private/test_labels.csv
          test -s data/private/test_labels.csv

      - name: Detect + validate submission files in this PR
        id: detect
        run: |
          set -e
          BASE_SHA="${{ github.event.pull_request.base.sha }}"
          HEAD_SHA="${{ github.event.pull_request.head.sha }}"

          CHANGED="$(git diff --name-only "$BASE_SHA" "$HEAD_SHA" || true)"

          # Block changes outside submission files
          BAD="$(echo "$CHANGED" | grep -vE '^submissions/inbox/.*/.*/(predictions\.csv|metadata\.json)$' || true)"
          if [ -n "$BAD" ]; then
            echo "❌ This PR can only add submission files."
            echo "Blocked changed files:"
            echo "$BAD"
            exit 1
          fi

          PRED="$(echo "$CHANGED" | grep -E '^submissions/inbox/.*/.*/predictions\.csv$' || true)"
          META="$(echo "$CHANGED" | grep -E '^submissions/inbox/.*/.*/metadata\.json$' || true)"

          PCOUNT="$(echo "$PRED" | sed '/^\s*$/d' | wc -l | tr -d ' ')"
          MCOUNT="$(echo "$META" | sed '/^\s*$/d' | wc -l | tr -d ' ')"

          if [ "$PCOUNT" -ne 1 ] || [ "$MCOUNT" -ne 1 ]; then
            echo "❌ Each PR must include exactly ONE predictions.csv and ONE metadata.json"
            echo "Found predictions: $PCOUNT, metadata: $MCOUNT"
            echo "Predictions:"
            echo "$PRED"
            echo "Metadata:"
            echo "$META"
            exit 1
          fi

          # Ensure they are in the same folder
          PDIR="$(dirname "$PRED")"
          MDIR="$(dirname "$META")"
          if [ "$PDIR" != "$MDIR" ]; then
            echo "❌ predictions.csv and metadata.json must be in the SAME run folder"
            echo "pred dir: $PDIR"
            echo "meta dir: $MDIR"
            exit 1
          fi

          echo "pred_file=$PRED" >> "$GITHUB_OUTPUT"
          echo "meta_file=$META" >> "$GITHUB_OUTPUT"
          echo "run_dir=$PDIR" >> "$GITHUB_OUTPUT"

      - name: Validate metadata.json content
        run: |
          set -e
          python scoring/validate_metadata.py "${{ steps.detect.outputs.meta_file }}"

      - name: Read metadata fields
        id: meta
        run: |
          set -e
          python - <<'PY'
          import json, os

          path = os.environ["META_PATH"]
          out_path = os.environ["GITHUB_OUTPUT"]

          with open(path, "r", encoding="utf-8") as f:
              d = json.load(f)

          team = str(d.get("team","")).strip()
          run_id = str(d.get("run_id","")).strip()
          author_type = str(d.get("author_type","")).strip().lower()
          model = str(d.get("model","")).strip()
          notes = str(d.get("notes","") or "").strip().replace("\n"," ").replace("\r"," ").strip()

          with open(out_path, "a", encoding="utf-8") as out:
              out.write(f"team={team}\n")
              out.write(f"run_id={run_id}\n")
              out.write(f"author_type={author_type}\n")
              out.write(f"model={model}\n")
              out.write(f"notes={notes}\n")
          PY
        env:
          META_PATH: ${{ steps.detect.outputs.meta_file }}

      - name: Enforce one submission per team
        shell: bash
        run: |
          set -e
          BASE_SHA="${{ github.event.pull_request.base.sha }}"
          TEAM="${{ steps.meta.outputs.team }}"

          if [ -z "$TEAM" ]; then
            echo "❌ Could not read team from metadata.json"
            exit 1
          fi

          if git cat-file -e "$BASE_SHA:leaderboard/leaderboard.csv" 2>/dev/null; then
            git show "$BASE_SHA:leaderboard/leaderboard.csv" > /tmp/leaderboard.csv
            python - <<'PY'
            import csv
            import os
            team = os.environ["TEAM"].strip().lower()
            if not team:
                raise SystemExit(1)
            with open("/tmp/leaderboard.csv", newline="", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if str(row.get("team","")).strip().lower() == team:
                        print("❌ This team already has a submission on the leaderboard.")
                        raise SystemExit(1)
            print("✅ Team has no prior submissions.")
            PY
          else
            echo "Leaderboard not found on base; skipping one-submission check."
          fi
        env:
          TEAM: ${{ steps.meta.outputs.team }}

      - name: Score submission (no leaderboard update)
        id: score
        run: |
          set -e
          python scoring/score_submission.py --pred "${{ steps.detect.outputs.pred_file }}" > score.txt
          cat score.txt

          SCORE="$(grep -Eo 'Macro-F1:\s*[0-9]+(\.[0-9]+)?' score.txt | head -n 1 | grep -Eo '[0-9]+(\.[0-9]+)?')"
          if [ -z "$SCORE" ]; then
            echo "❌ Could not parse score output."
            exit 1
          fi
          echo "macro_f1=$SCORE" >> "$GITHUB_OUTPUT"
